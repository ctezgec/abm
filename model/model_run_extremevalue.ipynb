{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Run For Extreme value**\n",
    "\n",
    "In this file, the model run as well as sensitivity analysis are conducted:\n",
    "\n",
    "1. Initial Model Run\n",
    "2. Extreme Value Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:05:34.692055Z",
     "start_time": "2024-01-29T22:05:32.279135Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary libraries and model\n",
    "from model import AdaptationModel\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import defaultdict \n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:05:34.695934Z",
     "start_time": "2024-01-29T22:05:34.691754Z"
    }
   },
   "outputs": [],
   "source": [
    "# set-up model parameters\n",
    "# run time: 100 years --> 400 quarters, so 400 ticks in total\n",
    "run_length = 400\n",
    "# set the number of replications \n",
    "replication_number = 5\n",
    "# set the number of households\n",
    "number_of_households = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial Run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:05:47.745349Z",
     "start_time": "2024-01-29T22:05:34.702132Z"
    }
   },
   "outputs": [],
   "source": [
    "# use defaultdict to store the results with different seeds\n",
    "model_results =  defaultdict(list)\n",
    "agent_results = defaultdict(list)\n",
    "# Run the model based on the parameters above, no subsidy included\n",
    "for i in range(replication_number):\n",
    "    seed = i  # set the seed\n",
    "    model = AdaptationModel(number_of_households= number_of_households,subsidy_rate= 0.5, income_threshold=4000, saving_threshold = 0.5, harvey_probability = 0.07, flood_map_choice=\"harvey\", network=\"no_network\", seed=seed)\n",
    "    for tick in range(run_length):\n",
    "        model.step() \n",
    "    model_data = model.datacollector.get_model_vars_dataframe()\n",
    "    agent_data = model.datacollector.get_agent_vars_dataframe()\n",
    "    model_results[i].append(model_data)\n",
    "    agent_results[i].append(agent_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:05:47.758223Z",
     "start_time": "2024-01-29T22:05:47.748888Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_to_dataframe(results, replication_number):\n",
    "    \"\"\"Convert the results to a dataframe, single index\"\"\"\n",
    "    dfs = [pd.concat(results[i], keys=[i], names=['replication/seed']) for i in range(replication_number)]\n",
    "    dataframe = pd.concat(dfs)\n",
    "    dataframe.reset_index(inplace=True)\n",
    "    dataframe.rename(columns={'level_1': 'Step'}, inplace=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:05:47.769944Z",
     "start_time": "2024-01-29T22:05:47.754259Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert the model results to dataframe\n",
    "model_dataframe = convert_to_dataframe(model_results, replication_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:05:47.798144Z",
     "start_time": "2024-01-29T22:05:47.771762Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the results to csv files\n",
    "model_dataframe.to_csv(f\"../result_extremevalue/{'model_results_initial'}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extreme Value Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:05:47.806851Z",
     "start_time": "2024-01-29T22:05:47.799856Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters for the sensitivity analysis\n",
    "subsidy_rate = [0, 0.25, 0.5, 0.75, 1]   # subsidy rate offered\n",
    "income_threshold = [0, 2000, 4000, 8000, 12000] # agents which have lower income then the threshold eligible for subsidy\n",
    "saving_threshold = [0, 0.25, 0.5, 0.75, 1] # agent calculate_saving(self) threshold, for saving or consuming\n",
    "flood_probabilities = [0.01, 0.03, 0.07, 0.3, 0.7, 1] # different flood probabilities for harvey map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Saving Threshold Extreme Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:06:40.862946Z",
     "start_time": "2024-01-29T22:05:47.803461Z"
    }
   },
   "outputs": [],
   "source": [
    "# use defaultdict to store the results with different seeds\n",
    "model_results_saving_threshold =  defaultdict(list)\n",
    "agent_results_saving_threshold = defaultdict(list)\n",
    "# Run the sensitivity for different saving thresholds, no subsidy included\n",
    "for rate in saving_threshold:\n",
    "    for i in range(replication_number):\n",
    "        seed = i  # set the seed\n",
    "        model = AdaptationModel(number_of_households= number_of_households,subsidy_rate= 0.5, income_threshold=4000, saving_threshold = rate, harvey_probability = 0.07, flood_map_choice=\"harvey\", network=\"no_network\", seed=seed)\n",
    "        for tick in range(run_length):\n",
    "            model.step() \n",
    "        model_data2 = model.datacollector.get_model_vars_dataframe()\n",
    "        agent_data2 = model.datacollector.get_agent_vars_dataframe()\n",
    "        agent_data2.reset_index(inplace=True)\n",
    "        model_results_saving_threshold[i,rate].append(model_data2)\n",
    "        agent_results_saving_threshold[i,rate].append(agent_data2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs = {}\n",
    "\n",
    "# Concatenate the dataframes for each (i, rate) key\n",
    "for key, result_list in model_results_saving_threshold.items():\n",
    "    i, rate = key\n",
    "    concatenated_dfs[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "model_dataframe_saving_threshold = pd.concat(concatenated_dfs.values(), keys=concatenated_dfs.keys(), names=['replication/seed', 'rate', 'Step'])\n",
    "\n",
    "# Reset the index \n",
    "model_dataframe_saving_threshold.reset_index(inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T22:06:40.864640Z",
     "start_time": "2024-01-29T22:06:40.811749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:06:44.114481Z",
     "start_time": "2024-01-29T22:06:40.818371Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs2 = {}\n",
    "\n",
    "# Concatenate the dataframes for each (i, rate) key\n",
    "for key, result_list in agent_results_saving_threshold.items():\n",
    "    i, rate = key\n",
    "    concatenated_dfs2[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "agent_dataframe_saving_threshold = pd.concat(concatenated_dfs2.values(), keys=concatenated_dfs2.keys(), names=['replication/seed', 'rate', 'index'])\n",
    "\n",
    "# Reset the index \n",
    "agent_dataframe_saving_threshold.reset_index(inplace=True)\n",
    "# drop index column\n",
    "agent_dataframe_saving_threshold.drop(columns=['index'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:06:44.176585Z",
     "start_time": "2024-01-29T22:06:44.113956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the results to csv files\n",
    "model_dataframe_saving_threshold.to_csv(f\"../result_extremevalue/{'model_sensitivity_results_saving_threshold'}.csv\", index=False)\n",
    "# agent_dataframe_saving_threshold.to_csv(f\"../result_extremevalue/{'agent_sensitivity_results_saving_threshold'}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:06:44.184250Z",
     "start_time": "2024-01-29T22:06:44.177615Z"
    }
   },
   "outputs": [],
   "source": [
    "#upload the data with the following code\n",
    "# change the file name to the file you want to load\n",
    "#model_dataframe_saving_threshold = pd.read_csv(f\"../result_extremevalue/{'model_sensitivity_results_saving_threshold'}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.Income Threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:07:36.769089Z",
     "start_time": "2024-01-29T22:06:44.182819Z"
    }
   },
   "outputs": [],
   "source": [
    "# use defaultdict to store the results with different seeds\n",
    "model_results_income_threshold =  defaultdict(list)\n",
    "agent_results_income_threshold = defaultdict(list)\n",
    "# Run the sensitivity for different income thresholds, when subsidy is 10% and saving threshold 0.25\n",
    "for income in income_threshold:\n",
    "    for i in range(replication_number):\n",
    "        seed = i  # set the seed\n",
    "        model = AdaptationModel(number_of_households= number_of_households,subsidy_rate= 0.5, income_threshold=income, saving_threshold = 0.5, harvey_probability = 0.07, flood_map_choice=\"harvey\", network=\"no_network\", seed=seed)\n",
    "        for tick in range(run_length):\n",
    "            model.step() \n",
    "        model_data3 = model.datacollector.get_model_vars_dataframe()\n",
    "        agent_data3 = model.datacollector.get_agent_vars_dataframe()\n",
    "        agent_data3.reset_index(inplace=True)\n",
    "        model_results_income_threshold[i,income].append(model_data3)\n",
    "        agent_results_income_threshold[i,income].append(agent_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:07:36.776662Z",
     "start_time": "2024-01-29T22:07:36.771410Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs = {}\n",
    "\n",
    "# Concatenate the dataframes for each key\n",
    "for key, result_list in model_results_income_threshold.items():\n",
    "    i, income = key\n",
    "    concatenated_dfs[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "model_dataframe_income_threshold = pd.concat(concatenated_dfs.values(), keys=concatenated_dfs.keys(), names=['replication/seed', 'income_threshold', 'Step'])\n",
    "\n",
    "# Reset the index \n",
    "model_dataframe_income_threshold.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:07:39.603645Z",
     "start_time": "2024-01-29T22:07:36.778593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs2 = {}\n",
    "\n",
    "# Concatenate the dataframes for each (i, rate) key\n",
    "for key, result_list in agent_results_income_threshold.items():\n",
    "    i, income = key\n",
    "    concatenated_dfs2[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "agent_dataframe_income_threshold = pd.concat(concatenated_dfs2.values(), keys=concatenated_dfs2.keys(), names=['replication/seed', 'income_threshold', 'index'])\n",
    "\n",
    "# Reset the index \n",
    "agent_dataframe_income_threshold.reset_index(inplace=True)\n",
    "# drop index column\n",
    "agent_dataframe_income_threshold.drop(columns=['index'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:07:39.659806Z",
     "start_time": "2024-01-29T22:07:39.604494Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the results to csv files\n",
    "model_dataframe_income_threshold.to_csv(f\"../result_extremevalue/{'model_sensitivity_results_income_threshold'}.csv\", index=False)\n",
    "# agent_dataframe_income_threshold.to_csv(f\"../result_extremevalue/{'agent_sensitivity_results_income_threshold'}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:07:39.667154Z",
     "start_time": "2024-01-29T22:07:39.660550Z"
    }
   },
   "outputs": [],
   "source": [
    "# upload the data with the following code\n",
    "# change the file name to the file you want to load\n",
    "# model_dataframe_income_threshold = pd.read_csv(f\"../result_extremevalue/{'model_sensitivity_results_income_threshold'}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.Subsidy Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:08:25.867601Z",
     "start_time": "2024-01-29T22:07:39.667608Z"
    }
   },
   "outputs": [],
   "source": [
    "# use defaultdict to store the results with different seeds\n",
    "model_results_subsidy_rate =  defaultdict(list)\n",
    "agent_results_subsidy_rate = defaultdict(list)\n",
    "# Run the sensitivity for different income thresholds, when income is 3000 and saving threshold 0.25\n",
    "for subsidy in subsidy_rate:\n",
    "    for i in range(replication_number):\n",
    "        seed = i  # set the seed\n",
    "        model = AdaptationModel(number_of_households= number_of_households,subsidy_rate= subsidy, income_threshold=4000, saving_threshold = 0.5, harvey_probability = 0.07, flood_map_choice=\"harvey\", network=\"no_network\", seed=seed)\n",
    "        for tick in range(run_length):\n",
    "            model.step() \n",
    "        model_data4 = model.datacollector.get_model_vars_dataframe()\n",
    "        agent_data4 = model.datacollector.get_agent_vars_dataframe()\n",
    "        agent_data4.reset_index(inplace=True)\n",
    "        model_results_subsidy_rate[i,subsidy].append(model_data4)\n",
    "        agent_results_subsidy_rate[i,subsidy].append(agent_data4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:08:25.882345Z",
     "start_time": "2024-01-29T22:08:25.871955Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs = {}\n",
    "\n",
    "# Concatenate the dataframes for each key\n",
    "for key, result_list in model_results_subsidy_rate.items():\n",
    "    i, subsidy = key\n",
    "    concatenated_dfs[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "model_dataframe_subsidy_rate = pd.concat(concatenated_dfs.values(), keys=concatenated_dfs.keys(), names=['replication/seed', 'subsidy_rate', 'Step'])\n",
    "\n",
    "# Reset the index \n",
    "model_dataframe_subsidy_rate.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:08:28.637396Z",
     "start_time": "2024-01-29T22:08:25.908449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs2 = {}\n",
    "\n",
    "# Concatenate the dataframes for each key\n",
    "for key, result_list in agent_results_subsidy_rate.items():\n",
    "    i, subsidy = key\n",
    "    concatenated_dfs2[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "agent_dataframe_subsidy_rate = pd.concat(concatenated_dfs2.values(), keys=concatenated_dfs2.keys(), names=['replication/seed', 'subsidy_rate', 'index'])\n",
    "\n",
    "# Reset the index \n",
    "agent_dataframe_subsidy_rate.reset_index(inplace=True)\n",
    "# drop index column\n",
    "agent_dataframe_subsidy_rate.drop(columns=['index'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:08:28.704538Z",
     "start_time": "2024-01-29T22:08:28.637051Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the results to csv files\n",
    "model_dataframe_subsidy_rate.to_csv(f\"../result_extremevalue/{'model_sensitivity_results_subsidy_rate'}.csv\", index=False)\n",
    "# agent_dataframe_subsidy_rate.to_csv(f\"../result_extremevalue/{'agent_sensitivity_results_subsidy_rate'}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:08:28.713908Z",
     "start_time": "2024-01-29T22:08:28.706099Z"
    }
   },
   "outputs": [],
   "source": [
    "# upload the data with the following code\n",
    "# change the file name to the file you want to load\n",
    "# model_dataframe_subsidy_rate = pd.read_csv(f\"../result_extremevalue/{'model_sensitivity_results_subsidy_rate'}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Flood Probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:09:19.505609Z",
     "start_time": "2024-01-29T22:08:28.714046Z"
    }
   },
   "outputs": [],
   "source": [
    "# use defaultdict to store the results with different seeds\n",
    "model_results_flood_prob =  defaultdict(list)\n",
    "agent_results_flood_prob = defaultdict(list)\n",
    "# Run the sensitivity for different flood prob, no subsidy included\n",
    "for prob in flood_probabilities:\n",
    "    for i in range(replication_number):\n",
    "        seed = i  # set the seed\n",
    "        model = AdaptationModel(number_of_households= number_of_households,subsidy_rate= 0.5, income_threshold=4000, saving_threshold = 0.5, harvey_probability = prob, flood_map_choice=\"harvey\", network=\"no_network\", seed=seed)\n",
    "        \n",
    "        for tick in range(run_length):\n",
    "            model.step() \n",
    "        model_data5 = model.datacollector.get_model_vars_dataframe()\n",
    "        agent_data5 = model.datacollector.get_agent_vars_dataframe()\n",
    "        agent_data5.reset_index(inplace=True)\n",
    "        model_results_flood_prob[i,prob].append(model_data5)\n",
    "        agent_results_flood_prob[i,prob].append(agent_data5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:09:19.584579Z",
     "start_time": "2024-01-29T22:09:19.507595Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs = {}\n",
    "\n",
    "# Concatenate the dataframes for each (i, rate) key\n",
    "for key, result_list in model_results_flood_prob.items():\n",
    "    i, prob = key\n",
    "    concatenated_dfs[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "model_dataframe_flood_prob = pd.concat(concatenated_dfs.values(), keys=concatenated_dfs.keys(), names=['replication/seed', 'flood_probability', 'Step'])\n",
    "\n",
    "# Reset the index \n",
    "model_dataframe_flood_prob.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:09:22.756814Z",
     "start_time": "2024-01-29T22:09:19.558924Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the concatenated dataframes\n",
    "concatenated_dfs2 = {}\n",
    "\n",
    "# Concatenate the dataframes for each (i, rate) key\n",
    "for key, result_list in agent_results_flood_prob.items():\n",
    "    i, prob = key\n",
    "    concatenated_dfs2[key] = pd.concat(result_list)\n",
    "\n",
    "# Convert the dictionary of dataframes to a single dataframe\n",
    "agent_dataframe_flood_prob = pd.concat(concatenated_dfs2.values(), keys=concatenated_dfs2.keys(), names=['replication/seed', 'flood_probability', 'index'])\n",
    "\n",
    "# Reset the index \n",
    "agent_dataframe_flood_prob.reset_index(inplace=True)\n",
    "# drop index column\n",
    "agent_dataframe_flood_prob.drop(columns=['index'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T22:09:22.853731Z",
     "start_time": "2024-01-29T22:09:22.755364Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the results to csv files\n",
    "model_dataframe_flood_prob.to_csv(f\"../result_extremevalue/{'model_sensitivity_results_flood_prob'}.csv\", index=False)\n",
    "# agent_dataframe_flood_prob.to_csv(f\"../result_extremevalue/{'agent_sensitivity_results_flood_prob'}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
